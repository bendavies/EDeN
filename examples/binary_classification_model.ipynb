{
 "metadata": {
  "name": "",
  "signature": "sha256:2d3787df7f10b35364e2630ff6d8b48558137cbb573d42c616dff10cddd9e680"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_uri(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
      "\n",
      "def rfam_uri(family_id):\n",
      "    return '%s.fa'%(family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF02275' #Hammerhead_HH9\n",
      "rfam_id = 'RF00871' #microRNA mir-689\n",
      "rfam_id = 'RF00005' #tRNA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "    graphs = rnafold_to_eden( data, **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( data, data_type='seq', **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
      "estimator = PassiveAggressiveClassifier(shuffle=True)\n",
      "estimator = Perceptron(class_weight='auto', shuffle=True)\n",
      "estimator = SGDClassifier(class_weight='auto', shuffle=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data setup\n",
      "size=200\n",
      "times=2\n",
      "train_test_split=0.7\n",
      "n_iter=30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "iterable_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=times, order=2 )\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size*times)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[1,2,3], \n",
      "                          'shape_type':[4,5], \n",
      "                          'energy_range':randint(10, 40, size=n_iter)}\n",
      "\n",
      "vectorizer_parameters={'complexity':[1,2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, n_iter=n_iter, cv=3, n_jobs=1, verbose=True,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)\n",
      "\n",
      "#save model\n",
      "model_fname='eden_model_%s'%rfam_id\n",
      "model.save(model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters range:\n",
        "Pre_processor:\n",
        "{'energy_range': array([16, 39, 16, 36, 35, 19, 35, 33, 36, 32, 26, 27, 26, 39, 11, 27, 39,\n",
        "       34, 20, 31, 36, 11, 13, 26, 12, 36, 39, 32, 32, 27]),\n",
        " 'max_num': [1, 2, 3],\n",
        " 'shape_type': [4, 5]}\n",
        "Vectorizer:\n",
        "{'complexity': [1, 2]}\n",
        "Estimator:\n",
        "{'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
        " 'eta0': [0.0001, 0.001, 0.01],\n",
        " 'l1_ratio': array([ 0.76954803,  0.42623406,  0.89827625,  0.80252868,  0.27209892,\n",
        "        0.46860734,  0.15397767,  0.45010399,  0.89929125,  0.73102479,\n",
        "        0.23887371,  0.67439377,  0.82355878,  0.21306252,  0.77436828,\n",
        "        0.12886963,  0.40612349,  0.70865428,  0.88958205,  0.34561532,\n",
        "        0.83704415,  0.5806802 ,  0.17736266,  0.56936869,  0.26979793,\n",
        "        0.32810192,  0.61809281,  0.19267615,  0.10763917,  0.82357366]),\n",
        " 'learning_rate': ['invscaling', 'constant', 'optimal'],\n",
        " 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        " 'n_iter': array([88, 35, 42, 22, 64, 81, 66, 17, 80, 74, 88, 69, 35, 42, 12, 16, 65,\n",
        "       20, 25, 44, 59, 93, 36, 17,  8, 51, 72, 11, 17, 91]),\n",
        " 'penalty': ['l1', 'l2', 'elasticnet'],\n",
        " 'power_t': array([ 0.69432573,  0.40447292,  0.64450683,  0.5885946 ,  0.68536073,\n",
        "        0.35125158,  0.43707412,  0.24973085,  0.83677125,  0.44151738,\n",
        "        0.31997159,  0.82268035,  0.57095561,  0.98824659,  0.47628199,\n",
        "        0.48942579,  0.90148552,  0.85545244,  0.62506223,  0.64950295,\n",
        "        0.92781417,  0.83434951,  0.31775882,  0.98325621,  0.78188696,\n",
        "        0.66873705,  0.1446958 ,  0.91694741,  0.49508103,  0.44391509])}\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 1/30 (at 24.9 sec; 0:00:24.889299)\n",
        "Best score (roc_auc): 0.813342 (0.828833 +- 0.015490)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 36, 'max_num': 1, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 0.01,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.34561532239410586,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 51,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.24973084529712919}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 139 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 2/30 (at 58.4 sec; 0:00:58.351806)\n",
        "Best score (roc_auc): 0.836952 (0.859146 +- 0.022194)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 32, 'max_num': 2, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 1e-05,\n",
        " 'eta0': 0.0001,\n",
        " 'l1_ratio': 0.19267615204809829,\n",
        " 'learning_rate': 'invscaling',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 88,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.83434950966380195}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 162 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 4/30 (at 135.3 sec; 0:02:15.336062)\n",
        "Best score (roc_auc): 0.885153 (0.889632 +- 0.004479)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 32, 'max_num': 3, 'shape_type': 5}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 0.001,\n",
        " 'eta0': 0.01,\n",
        " 'l1_ratio': 0.80252867988088572,\n",
        " 'learning_rate': 'invscaling',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 65,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.35125157617269887}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 192 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Models can be reloaded from disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "model2 = ActiveLearningBinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ActiveLearningBinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "iterable_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=times, order=2 )\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size*times)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[1,2,3], \n",
      "                          'shape_type':[4,5], \n",
      "                          'energy_range':randint(10, 40, size=n_iter)}\n",
      "\n",
      "vectorizer_parameters={'complexity':[1,2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "active_set_size=50\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, \n",
      "               n_active_learning_iterations=4,\n",
      "               size_positive=-1,\n",
      "               size_negative=active_set_size,\n",
      "               n_iter=n_iter, cv=3, n_jobs=1, verbose=True,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)\n",
      "\n",
      "#save model\n",
      "model_fname='eden_model_active_%s'%rfam_id\n",
      "model.save(model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "model2 = ActiveLearningBinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}