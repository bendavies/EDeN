{
 "metadata": {
  "name": "",
  "signature": "sha256:5c671d3177cdedee70f1bcd0f93ca2f728d48fd5396e79707c2015915459ba50"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_uri(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
      "\n",
      "def rfam_uri(family_id):\n",
      "    return '%s.fa'%(family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF02275' #Hammerhead_HH9\n",
      "rfam_id = 'RF00871' #microRNA mir-689\n",
      "rfam_id = 'RF00005' #tRNA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "    graphs = rnafold_to_eden( data, **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( data, data_type='seq', **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
      "estimator = PassiveAggressiveClassifier(shuffle=True)\n",
      "estimator = Perceptron(class_weight='auto', shuffle=True)\n",
      "estimator = SGDClassifier(class_weight='auto', shuffle=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data setup\n",
      "size=200\n",
      "times=2\n",
      "train_test_split=0.7\n",
      "n_iter=30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "iterable_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=times, order=2 )\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size*times)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[1,2,3], \n",
      "                          'shape_type':[4,5], \n",
      "                          'energy_range':randint(10, 40, size=n_iter)}\n",
      "\n",
      "vectorizer_parameters={'complexity':[1,2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, n_iter=n_iter, cv=3, n_jobs=1, verbose=True,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)\n",
      "\n",
      "#save model\n",
      "model_fname='eden_model_%s'%rfam_id\n",
      "model.save(model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Parameters range:\n",
        "Pre_processor:\n",
        "{'energy_range': array([16, 39, 16, 36, 35, 19, 35, 33, 36, 32, 26, 27, 26, 39, 11, 27, 39,\n",
        "       34, 20, 31, 36, 11, 13, 26, 12, 36, 39, 32, 32, 27]),\n",
        " 'max_num': [1, 2, 3],\n",
        " 'shape_type': [4, 5]}\n",
        "Vectorizer:\n",
        "{'complexity': [1, 2]}\n",
        "Estimator:\n",
        "{'alpha': [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1],\n",
        " 'eta0': [0.0001, 0.001, 0.01],\n",
        " 'l1_ratio': array([ 0.76954803,  0.42623406,  0.89827625,  0.80252868,  0.27209892,\n",
        "        0.46860734,  0.15397767,  0.45010399,  0.89929125,  0.73102479,\n",
        "        0.23887371,  0.67439377,  0.82355878,  0.21306252,  0.77436828,\n",
        "        0.12886963,  0.40612349,  0.70865428,  0.88958205,  0.34561532,\n",
        "        0.83704415,  0.5806802 ,  0.17736266,  0.56936869,  0.26979793,\n",
        "        0.32810192,  0.61809281,  0.19267615,  0.10763917,  0.82357366]),\n",
        " 'learning_rate': ['invscaling', 'constant', 'optimal'],\n",
        " 'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        " 'n_iter': array([88, 35, 42, 22, 64, 81, 66, 17, 80, 74, 88, 69, 35, 42, 12, 16, 65,\n",
        "       20, 25, 44, 59, 93, 36, 17,  8, 51, 72, 11, 17, 91]),\n",
        " 'penalty': ['l1', 'l2', 'elasticnet'],\n",
        " 'power_t': array([ 0.69432573,  0.40447292,  0.64450683,  0.5885946 ,  0.68536073,\n",
        "        0.35125158,  0.43707412,  0.24973085,  0.83677125,  0.44151738,\n",
        "        0.31997159,  0.82268035,  0.57095561,  0.98824659,  0.47628199,\n",
        "        0.48942579,  0.90148552,  0.85545244,  0.62506223,  0.64950295,\n",
        "        0.92781417,  0.83434951,  0.31775882,  0.98325621,  0.78188696,\n",
        "        0.66873705,  0.1446958 ,  0.91694741,  0.49508103,  0.44391509])}\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 1/30 (at 24.9 sec; 0:00:24.889299)\n",
        "Best score (roc_auc): 0.813342 (0.828833 +- 0.015490)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 36, 'max_num': 1, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 0.01,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.34561532239410586,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 51,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.24973084529712919}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 139 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 2/30 (at 58.4 sec; 0:00:58.351806)\n",
        "Best score (roc_auc): 0.836952 (0.859146 +- 0.022194)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 32, 'max_num': 2, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 1e-05,\n",
        " 'eta0': 0.0001,\n",
        " 'l1_ratio': 0.19267615204809829,\n",
        " 'learning_rate': 'invscaling',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 88,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.83434950966380195}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 162 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 4/30 (at 135.3 sec; 0:02:15.336062)\n",
        "Best score (roc_auc): 0.885153 (0.889632 +- 0.004479)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 32, 'max_num': 3, 'shape_type': 5}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 0.001,\n",
        " 'eta0': 0.01,\n",
        " 'l1_ratio': 0.80252867988088572,\n",
        " 'learning_rate': 'invscaling',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 65,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.35125157617269887}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 192 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 5/30 (at 156.9 sec; 0:02:36.942868)\n",
        "Best score (roc_auc): 0.889840 (0.920271 +- 0.030431)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 26, 'max_num': 1, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 1e-06,\n",
        " 'eta0': 0.01,\n",
        " 'l1_ratio': 0.12886963260118778,\n",
        " 'learning_rate': 'constant',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 59,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.85545244088149941}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 139 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 12/30 (at 473.7 sec; 0:07:53.707465)\n",
        "Best score (roc_auc): 0.901088 (0.921128 +- 0.020040)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 26, 'max_num': 2, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 1e-07,\n",
        " 'eta0': 0.01,\n",
        " 'l1_ratio': 0.73102479417066868,\n",
        " 'learning_rate': 'constant',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 16,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.83677125402284447}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 162 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 13/30 (at 563.2 sec; 0:09:23.232801)\n",
        "Best score (roc_auc): 0.911940 (0.923108 +- 0.011168)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 35, 'max_num': 3, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 2}\n",
        "Estimator:\n",
        "{'alpha': 0.0001,\n",
        " 'eta0': 0.001,\n",
        " 'l1_ratio': 0.76954803207291966,\n",
        " 'learning_rate': 'invscaling',\n",
        " 'loss': 'perceptron',\n",
        " 'n_iter': 72,\n",
        " 'penalty': 'l1',\n",
        " 'power_t': 0.43707412315205985}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 837 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 14/30 (at 628.2 sec; 0:10:28.165432)\n",
        "Best score (roc_auc): 0.944118 (0.963072 +- 0.018953)\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 32, 'max_num': 2, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 2}\n",
        "Estimator:\n",
        "{'alpha': 1e-07,\n",
        " 'eta0': 0.01,\n",
        " 'l1_ratio': 0.15397766729499765,\n",
        " 'learning_rate': 'constant',\n",
        " 'loss': 'modified_huber',\n",
        " 'n_iter': 65,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.44391508697751458}\n",
        "Instances: 840 ; Features: 1048577 with an avg of 695 features per instance\n",
        "class: 1 count:280 (0.33)\tclass: -1 count:560 (0.67)\t\n",
        "Failed iteration: 23/30 (at 1004.1 sec; 0:16:44.070993)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inappropriate argument value (of correct type).\n",
        "Floating-point under-/overflow occurred at epoch #1. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
        "Failed with the following setting:\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 32, 'max_num': 3, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 1e-08,\n",
        " 'eta0': 0.0001,\n",
        " 'l1_ratio': 0.80252867988088572,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'squared_hinge',\n",
        " 'n_iter': 35,\n",
        " 'penalty': 'elasticnet',\n",
        " 'power_t': 0.35125157617269887}\n",
        "...continuing\n",
        "Failed iteration: 28/30 (at 1186.3 sec; 0:19:46.296818)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inappropriate argument value (of correct type).\n",
        "Floating-point under-/overflow occurred at epoch #1. Scaling input data with StandardScaler or MinMaxScaler might help.\n",
        "Failed with the following setting:\n",
        "Current parameters:\n",
        "Pre_processor:\n",
        "{'energy_range': 26, 'max_num': 2, 'shape_type': 4}\n",
        "Vectorizer:\n",
        "{'complexity': 1}\n",
        "Estimator:\n",
        "{'alpha': 1e-08,\n",
        " 'eta0': 0.0001,\n",
        " 'l1_ratio': 0.77436827895253046,\n",
        " 'learning_rate': 'optimal',\n",
        " 'loss': 'squared_hinge',\n",
        " 'n_iter': 42,\n",
        " 'penalty': 'l2',\n",
        " 'power_t': 0.64950295009006087}\n",
        "...continuing\n",
        "CPU times: user 15min 6s, sys: 59.5 s, total: 16min 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 21min 35s\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier:\n",
        "SGDClassifier(alpha=1e-07, class_weight='auto', epsilon=0.1, eta0=0.01,\n",
        "       fit_intercept=True, l1_ratio=0.15397766729499765,\n",
        "       learning_rate='constant', loss='modified_huber', n_iter=65,\n",
        "       n_jobs=1, penalty='elasticnet', power_t=0.44391508697751458,\n",
        "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
        "--------------------------------------------------------------------------------\n",
        "Predictive performance:\n",
        "            accuracy: 0.833 +- 0.066"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "           precision: 0.884 +- 0.148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              recall: 0.617 +- 0.155"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                  f1: 0.697 +- 0.087"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   average_precision: 0.870 +- 0.077"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             roc_auc: 0.899 +- 0.064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "--------------------------------------------------------------------------------\n",
        "CPU times: user 36.2 s, sys: 1.32 s, total: 37.5 s\n",
        "Wall time: 41.8 s\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Models can be reloaded from disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "model2 = ActiveLearningBinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 -0.724949361057\n",
        "1 -0.724949361057\n",
        "2 -0.59537664129\n",
        "3 -0.59537664129\n",
        "4 -0.50086416475\n",
        "5 -0.50086416475\n",
        "6 -0.388563883564\n",
        "7 -0.388563883564\n",
        "8 -0.218071933411\n",
        "9 -0.218071933411\n",
        "10 -0.16780342045\n",
        "11 -0.16780342045\n",
        "12 -0.152595082194\n",
        "13 -0.152595082194\n",
        "14 -0.139171730365\n",
        "15 -0.139171730365\n",
        "16 -0.0770464736316\n",
        "17 -0.0770464736316\n",
        "18 -0.0717570488631\n",
        "19 -0.0717570488631\n",
        "20 -0.0087039000011\n",
        "21 -0.0087039000011\n",
        "22 0.00652354636424\n",
        "23 0.00652354636424\n",
        "24 0.0177074410556\n",
        "25 0.0177074410556\n",
        "26 0.0443759693567\n",
        "27 0.0443759693567\n",
        "28 0.21331530388\n",
        "29 0.21331530388\n",
        "30 0.222855526866\n",
        "31 0.222855526866\n",
        "32 0.237406102104\n",
        "33 0.237406102104\n",
        "34 0.239893731389\n",
        "35 0.239893731389\n",
        "36 0.282517616208\n",
        "37 0.282517616208\n",
        "38 0.298696801088\n",
        "39 0.298696801088\n",
        "40 0.342687719933\n",
        "41 0.342687719933\n",
        "42 0.402201421629\n",
        "43 0.402201421629\n",
        "44 0.41058729082\n",
        "45 0.41058729082\n",
        "46 0.417613301524\n",
        "47 0.417613301524\n",
        "48 0.428129122023\n",
        "49 0.428129122023\n",
        "50 0.448969841626\n",
        "51 0.448969841626\n",
        "52 0.510041831579\n",
        "53 0.510041831579\n",
        "54 0.554815693593\n",
        "55 0.554815693593\n",
        "56 0.574127798728\n",
        "57 0.574127798728\n",
        "58 0.590921930556\n",
        "59 0.590921930556\n",
        "60 0.622839657553\n",
        "61 0.622839657553\n",
        "62 0.632043523446\n",
        "63 0.632043523446\n",
        "64 0.636675391929\n",
        "65 0.636675391929\n",
        "66 0.636677002343\n",
        "67 0.636677002343\n",
        "68 0.652669492522\n",
        "69 0.652669492522\n",
        "70 0.655589690349\n",
        "71 0.655589690349\n",
        "72 0.663738109362\n",
        "73 0.663738109362\n",
        "74 0.665585124239\n",
        "75 0.665585124239\n",
        "76 0.694093884603\n",
        "77 0.694093884603\n",
        "78 0.709296313731\n",
        "79 0.709296313731\n",
        "80 0.721912419501\n",
        "81 0.721912419501\n",
        "82 0.722876857092\n",
        "83 0.722876857092\n",
        "84 0.723396549291\n",
        "85 0.723396549291\n",
        "86 0.725791847982\n",
        "87 0.725791847982\n",
        "88 0.728456680198\n",
        "89 0.728456680198\n",
        "90 0.728678020277\n",
        "91 0.728678020277\n",
        "92 0.731196157857\n",
        "93 0.731196157857\n",
        "94 0.7313258388\n",
        "95 0.7313258388\n",
        "96 0.744377262073\n",
        "97 0.744377262073\n",
        "98 0.74652904942\n",
        "99 0.74652904942\n",
        "100 0.746896476781\n",
        "101 0.746896476781\n",
        "102 0.751552658914\n",
        "103 0.751552658914\n",
        "104 0.757605139593\n",
        "105 0.757605139593\n",
        "106 0.761610475257\n",
        "107 0.761610475257\n",
        "108 0.767947424286\n",
        "109 0.767947424286\n",
        "110 0.770094836639\n",
        "111 0.770094836639\n",
        "112 0.774825564912\n",
        "113 0.774825564912\n",
        "114 0.777191706746\n",
        "115 0.777191706746\n",
        "116 0.787021213662\n",
        "117 0.787021213662\n",
        "118 0.795384947024\n",
        "119 0.795384947024\n",
        "120 0.798207906309\n",
        "121 0.798207906309\n",
        "122 0.803520907889\n",
        "123 0.803520907889\n",
        "124 0.807055746675\n",
        "125 0.807055746675\n",
        "126 0.812929030372\n",
        "127 0.812929030372\n",
        "128 0.813105448653\n",
        "129 0.813105448653\n",
        "130 0.825088452785\n",
        "131 0.825088452785\n",
        "132 0.826536751994\n",
        "133 0.826536751994\n",
        "134 0.830767084556\n",
        "135 0.830767084556\n",
        "136 0.835888874148\n",
        "137 0.835888874148\n",
        "138 0.837493161996\n",
        "139 0.837493161996\n",
        "140 0.838435205014\n",
        "141 0.838435205014\n",
        "142 0.838642461963\n",
        "143 0.838642461963\n",
        "144 0.838928506073\n",
        "145 0.838928506073\n",
        "146 0.846165242015\n",
        "147 0.846165242015\n",
        "148 0.846790438158\n",
        "149 0.846790438158\n",
        "150 0.85009415119\n",
        "151 0.85009415119\n",
        "152 0.856331217513\n",
        "153 0.856331217513\n",
        "154 0.86093888978\n",
        "155 0.86093888978\n",
        "156 0.861437099372\n",
        "157 0.861437099372\n",
        "158 0.861924301416\n",
        "159 0.861924301416\n",
        "160 0.871058608163\n",
        "161 0.871058608163\n",
        "162 0.877584082282\n",
        "163 0.877584082282\n",
        "164 0.882031542303\n",
        "165 0.882031542303\n",
        "166 0.88346190578\n",
        "167 0.88346190578\n",
        "168 0.885632541087\n",
        "169 0.885632541087\n",
        "170 0.886332830096\n",
        "171 0.886332830096\n",
        "172 0.890557220466\n",
        "173 0.890557220466\n",
        "174 0.895310895163\n",
        "175 0.895310895163\n",
        "176 0.895551390844\n",
        "177 0.895551390844\n",
        "178 0.897339871474\n",
        "179 0.897339871474\n",
        "180 0.898672641629\n",
        "181 0.898672641629\n",
        "182 0.899935715716\n",
        "183 0.899935715716\n",
        "184 0.901339534581\n",
        "185 0.901339534581\n",
        "186 0.90388352542\n",
        "187 0.90388352542\n",
        "188 0.903958078469\n",
        "189 0.903958078469\n",
        "190 0.904065980938\n",
        "191 0.904065980938\n",
        "192 0.917148794619\n",
        "193 0.917148794619\n",
        "194 0.920326017354\n",
        "195 0.920326017354\n",
        "196 0.922257203758\n",
        "197 0.922257203758\n",
        "198 0.926418468373\n",
        "199 0.926418468373\n",
        "200 0.929112689148\n",
        "201 0.929112689148\n",
        "202 0.92950748272\n",
        "203 0.92950748272\n",
        "204 0.932879026533\n",
        "205 0.932879026533\n",
        "206 0.933663698179\n",
        "207 0.933663698179\n",
        "208 0.936352980789\n",
        "209 0.936352980789\n",
        "210 0.940271836222\n",
        "211 0.940271836222\n",
        "212 0.940789519206\n",
        "213 0.940789519206\n",
        "214 0.941304643926\n",
        "215 0.941304643926\n",
        "216 0.944516566814\n",
        "217 0.944516566814\n",
        "218 0.949519710594\n",
        "219 0.949519710594\n",
        "220 0.95253682909\n",
        "221 0.95253682909\n",
        "222 0.952925604437\n",
        "223 0.952925604437\n",
        "224 0.953297123278\n",
        "225 0.953297123278\n",
        "226 0.957185392215\n",
        "227 0.957185392215\n",
        "228 0.961374114296\n",
        "229 0.961374114296\n",
        "230 0.962203647513\n",
        "231 0.962203647513\n",
        "232 0.965761207041\n",
        "233 0.965761207041\n",
        "234 0.966058897058\n",
        "235 0.966058897058\n",
        "236 0.967282881514\n",
        "237 0.967282881514\n",
        "238 0.967425721787\n",
        "239 0.967425721787\n",
        "240 0.973240170619\n",
        "241 0.973240170619\n",
        "242 0.976233695548\n",
        "243 0.976233695548\n",
        "244 0.979040023792\n",
        "245 0.979040023792\n",
        "246 0.985168368559\n",
        "247 0.985168368559\n",
        "248 0.987100526706\n",
        "249 0.987100526706\n",
        "250 0.988691000676\n",
        "251 0.988691000676\n",
        "252 0.990115942321\n",
        "253 0.990115942321\n",
        "254 0.990922970205\n",
        "255 0.990922970205\n",
        "256 0.99239054892\n",
        "257 0.99239054892\n",
        "258 0.992575875512\n",
        "259 0.992575875512\n",
        "260 0.996261644755\n",
        "261 0.996261644755\n",
        "262 0.996572670691\n",
        "263 0.996572670691\n",
        "264 0.996597219413\n",
        "265 0.996597219413\n",
        "266 0.999164442595\n",
        "267 0.999164442595\n",
        "268 1.00447107636\n",
        "269 1.00447107636\n",
        "270 1.00526398877\n",
        "271 1.00526398877\n",
        "272 1.00667695703\n",
        "273 1.00667695703\n",
        "274 1.0155303726\n",
        "275 1.0155303726\n",
        "276 1.0189766353\n",
        "277 1.0189766353\n",
        "278 1.01933201389\n",
        "279 1.01933201389\n",
        "280 1.02320401827\n",
        "281 1.02320401827\n",
        "282 1.02435820942\n",
        "283 1.02435820942\n",
        "284 1.02576711211\n",
        "285 1.02576711211\n",
        "286 1.02998635829\n",
        "287 1.02998635829\n",
        "288 1.03059155729\n",
        "289 1.03059155729\n",
        "290 1.03093309832\n",
        "291 1.03093309832\n",
        "292 1.03099137948\n",
        "293 1.03099137948\n",
        "294 1.03668838365\n",
        "295 1.03668838365\n",
        "296 1.03757414704\n",
        "297 1.03757414704\n",
        "298 1.04702552659\n",
        "299 1.04702552659\n",
        "300 1.05000989618\n",
        "301 1.05000989618\n",
        "302 1.05346236339\n",
        "303 1.05346236339\n",
        "304 1.06469530719\n",
        "305 1.06469530719\n",
        "306 1.06545609546\n",
        "307 1.06545609546\n",
        "308 1.06943740385\n",
        "309 1.06943740385\n",
        "310 1.07093748009\n",
        "311 1.07093748009\n",
        "312 1.08065240112\n",
        "313 1.08065240112\n",
        "314 1.08067213608\n",
        "315 1.08067213608\n",
        "316 1.0841428279\n",
        "317 1.0841428279\n",
        "318 1.08895127381\n",
        "319 1.08895127381\n",
        "320 1.0938584142\n",
        "321 1.0938584142\n",
        "322 1.109214669\n",
        "323 1.109214669\n",
        "324 1.12297454676\n",
        "325 1.12297454676\n",
        "326 1.12558253013\n",
        "327 1.12558253013\n",
        "328 1.12655099303\n",
        "329 1.12655099303\n",
        "330 1.12687703041\n",
        "331 1.12687703041\n",
        "332 1.14868327824\n",
        "333 1.14868327824\n",
        "334 1.16832601958\n",
        "335 1.16832601958\n",
        "336 1.16880831105\n",
        "337 1.16880831105\n",
        "338 1.17345042873\n",
        "339 1.17345042873\n",
        "340 1.1820355197\n",
        "341 1.1820355197\n",
        "342 1.18473072665\n",
        "343 1.18473072665\n",
        "344 1.19246788405\n",
        "345 1.19246788405\n",
        "346 1.20580249731\n",
        "347 1.20580249731\n",
        "348 1.21208511173\n",
        "349 1.21208511173\n",
        "350 1.21236056164\n",
        "351 1.21236056164\n",
        "352 1.26627046256\n",
        "353 1.26627046256\n",
        "354 1.26711896481\n",
        "355 1.26711896481\n",
        "356 1.28467603407\n",
        "357 1.28467603407\n",
        "358 1.28747443722\n",
        "359 1.28747443722\n",
        "360 1.29573817129\n",
        "361 1.29573817129\n",
        "362 1.2973517553\n",
        "363 1.2973517553\n",
        "364 1.31525600379\n",
        "365 1.31525600379\n",
        "366 1.3202335736\n",
        "367 1.3202335736\n",
        "368 1.32649275584\n",
        "369 1.32649275584\n",
        "370 1.32988219155\n",
        "371 1.32988219155\n",
        "372 1.33739621611\n",
        "373 1.33739621611\n",
        "374 1.34784482157\n",
        "375 1.34784482157\n",
        "376 1.35951599149\n",
        "377 1.35951599149\n",
        "378 1.40196889117\n",
        "379 1.40196889117\n",
        "380 1.42409828897\n",
        "381 1.42409828897\n",
        "382 1.42418190941\n",
        "383 1.42418190941\n",
        "384 1.46248756476\n",
        "385 1.46248756476\n",
        "386 1.47527993267\n",
        "387 1.47527993267\n",
        "388 1.47554761446\n",
        "389 1.47554761446\n",
        "390 1.51091325702\n",
        "391 1.51091325702\n",
        "392 1.51844351553\n",
        "393 1.51844351553\n",
        "394 1.52139585246\n",
        "395 1.52139585246\n",
        "396 1.58589279107\n",
        "397 1.58589279107\n",
        "398 1.64366209305\n",
        "399 1.64366209305\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ActiveLearningBinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "from eden.modifier.seq import seq_to_seq, shuffle_modifier\n",
      "iterable_neg = seq_to_seq( seqs_, modifier=shuffle_modifier, times=times, order=2 )\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size*times)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[1,2,3], \n",
      "                          'shape_type':[4,5], \n",
      "                          'energy_range':randint(10, 40, size=n_iter)}\n",
      "\n",
      "vectorizer_parameters={'complexity':[1,2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "active_set_size=50\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, \n",
      "               n_active_learning_iterations=4,\n",
      "               size_positive=-1,\n",
      "               size_negative=active_set_size,\n",
      "               n_iter=n_iter, cv=3, n_jobs=1, verbose=True,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)\n",
      "\n",
      "#save model\n",
      "model_fname='eden_model_active_%s'%rfam_id\n",
      "model.save(model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "\n",
      "model2 = ActiveLearningBinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "from eden.converter.fasta import fasta_to_sequence\n",
      "seqs = fasta_to_sequence( rfam_uri( rfam_id ) )\n",
      "from itertools import tee\n",
      "seqs,seqs_=tee(seqs)\n",
      "iterable_pos = seqs\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}