{
 "metadata": {
  "name": "",
  "signature": "sha256:cb379938f16391c3823be96673efcad0aec4a9981b2379932b10342abae551f0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rfam_uri(family_id):\n",
      "    return 'http://rfam.xfam.org/family/%s/alignment?acc=%s&format=fastau&download=0'%(family_id,family_id)\n",
      "\n",
      "def rfam_uri(family_id):\n",
      "    return '%s.fa'%(family_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rfam_id = 'RF02275' #Hammerhead_HH9\n",
      "rfam_id = 'RF00871' #microRNA mir-689\n",
      "rfam_id = 'RF00005' #tRNA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnafold import rnafold_to_eden\n",
      "    graphs = rnafold_to_eden( data, **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pre_processor( data, **args):\n",
      "    from eden.converter.rna.rnashapes import rnashapes_to_eden\n",
      "    graphs = rnashapes_to_eden( data, data_type='seq', **args )\n",
      "    return graphs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.graph import Vectorizer\n",
      "vectorizer = Vectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier, Perceptron, PassiveAggressiveClassifier\n",
      "estimator = PassiveAggressiveClassifier(shuffle=True)\n",
      "estimator = Perceptron(class_weight='auto', shuffle=True)\n",
      "estimator = SGDClassifier(class_weight='auto', shuffle=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data setup\n",
      "size=200\n",
      "train_test_split=0.7\n",
      "n_iter=30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "iterable_pos = fasta_to_fasta( rfam_uri( rfam_id ) )\n",
      "iterable_neg = fasta_to_fasta( rfam_uri( rfam_id ) , modifier=shuffle_modifier, times=1, order=2 )\n",
      "\n",
      "from eden.converter.fasta import fasta_to_seq\n",
      "iterable_pos = fasta_to_seq(iterable_pos)\n",
      "iterable_neg = fasta_to_seq(iterable_neg)\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import BinaryClassificationModel\n",
      "model = BinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[1,2,3], \n",
      "                          'shape_type':[4,5], \n",
      "                          'energy_range':randint(10, 40, size=n_iter)}\n",
      "\n",
      "vectorizer_parameters={'complexity':[1,2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, n_iter=n_iter, cv=3, n_jobs=1, verbose=True,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)\n",
      "\n",
      "#save model\n",
      "model_fname='eden_model_%s'%rfam_id\n",
      "model.save(model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (model.py, line 142)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"/Users/costa/Desktop/BTSync/Projects/EDeN/EDeN/eden/model.py\"\u001b[0;36m, line \u001b[0;32m142\u001b[0m\n\u001b[0;31m    print e.__doc__\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Models can be reloaded from disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from eden.model import BinaryClassificationModel\n",
      "\n",
      "model2 = BinaryClassificationModel()\n",
      "model2.load(model_fname)\n",
      "\n",
      "#create iterable from files\n",
      "from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "iterable_pos = fasta_to_fasta( rfam_uri( rfam_id ) )\n",
      "\n",
      "from eden.converter.fasta import fasta_to_seq\n",
      "iterable_pos = fasta_to_seq(iterable_pos)\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "\n",
      "predictions= model2.decision_function( iterable_pos )\n",
      "for n,i in enumerate(sorted(predictions)): print n,i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#ActiveLearningBinaryClassificationModel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create iterable from files\n",
      "from eden.modifier.fasta import fasta_to_fasta, shuffle_modifier\n",
      "iterable_pos = fasta_to_fasta( rfam_uri( rfam_id ) )\n",
      "iterable_neg = fasta_to_fasta( rfam_uri( rfam_id ) , modifier=shuffle_modifier, times=1, order=2 )\n",
      "\n",
      "from eden.converter.fasta import fasta_to_seq\n",
      "iterable_pos = fasta_to_seq(iterable_pos)\n",
      "iterable_neg = fasta_to_seq(iterable_neg)\n",
      "\n",
      "#consier only first 'size' elements\n",
      "from itertools import islice\n",
      "iterable_pos = islice(iterable_pos,size)\n",
      "iterable_neg = islice(iterable_neg,size)\n",
      "\n",
      "#split train/test\n",
      "from eden.util import random_bipartition_iter\n",
      "iterable_pos_train, iterable_pos_test = random_bipartition_iter(iterable_pos, relative_size=train_test_split)\n",
      "iterable_neg_train, iterable_neg_test = random_bipartition_iter(iterable_neg, relative_size=train_test_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#make predictive model\n",
      "from eden.model import ActiveLearningBinaryClassificationModel\n",
      "model = ActiveLearningBinaryClassificationModel( pre_processor, estimator=estimator, vectorizer=vectorizer )\n",
      "\n",
      "#optimize hyperparameters and fit model\n",
      "from numpy.random import randint\n",
      "from numpy.random import uniform\n",
      "pre_processor_parameters={'max_num':[1,2,3], \n",
      "                          'shape_type':[4,5], \n",
      "                          'energy_range':randint(10, 40, size=n_iter)}\n",
      "\n",
      "vectorizer_parameters={'complexity':[1,2]}\n",
      "\n",
      "estimator_parameters={'n_iter':randint(5, 100, size=n_iter),\n",
      "                      'penalty':['l1','l2','elasticnet'],\n",
      "                      'l1_ratio':uniform(0.1,0.9, size=n_iter), \n",
      "                      'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
      "                      'power_t':uniform(0.1, size=n_iter),\n",
      "                      'alpha': [10**x for x in range(-8,0)],\n",
      "                      'eta0': [10**x for x in range(-4,-1)],\n",
      "                      'learning_rate': [\"invscaling\", \"constant\", \"optimal\"]}\n",
      "active_set_size=50\n",
      "model.optimize(iterable_pos_train, iterable_neg_train, \n",
      "               n_active_learning_iterations=3,\n",
      "               size_positive=-1,\n",
      "               size_negative=active_set_size,\n",
      "               n_iter=n_iter, cv=3, n_jobs=1, verbose=True,\n",
      "               pre_processor_parameters=pre_processor_parameters, \n",
      "               vectorizer_parameters=vectorizer_parameters, \n",
      "               estimator_parameters=estimator_parameters)\n",
      "\n",
      "#save model\n",
      "model_fname='eden_model_%s'%rfam_id\n",
      "model.save(model_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#estimate predictive performance\n",
      "model.estimate( iterable_pos_test, iterable_neg_test, cv=5 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}